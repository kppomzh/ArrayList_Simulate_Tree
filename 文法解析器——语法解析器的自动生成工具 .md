文法解析器——语法解析器的自动生成工具
=================
※推荐使用Typora及Fira Code字体来阅读本文档,以获得最佳阅读效果

# 开发构想
本项目在思路上部分仿照Antlr v4，本来计划单独写一个SQL语言解析成语法树的项目，为此重新翻书学习写教程。   
但是在重新学习的过程中，觉得即使写一个灵活的按照文法生成代码的工具似乎也并不是那么难。  
并且哪怕为是精简再精简的SQL的LL(1)文法手工构造一个分析表也是一件非常繁难艰巨毫无趣味的重复工作。于是就动了写个程序自动填分析表的念头。  
再后来想到仅仅有分析表判断语法是否正确对之后的分析工作毫无作用，于是又开始着手构造AST的数据结构；但是手动构造所有文法产生式的子AST一样也很麻烦，
就再次扩展了自动填表程序的功能。  
最后想着反正语法分析的代码生成都要自动化了，索性顺手把词法分析的关键字表一起填了吧。就变成了现在这个样子。

# 看懂各节代码需要的前置理论索引
1. 词法分析：状态模式、有限自动机、正则文法与有限自动机的等价性
2. 语法分析：表驱动法、下推有限自动机、上下文无关文法与下推有限自动机的等价性
3. 文法规则解析：LL预测分析程序原理、基础图论、关系及其闭包、树的遍历
4. 文法性质归纳与检查：上下文无关文法的化简、命题逻辑、演绎推理、可判定性
5. AST类自动生成：反射、模板代码生成

# 概念定义
1. AST：AST是"Abstract Syntax Tree"的缩写，汉语意思是“抽象语法树”，和项目名称没有任何关系。
2. 文法符号：用来构建不同分析层次的标记符号，目的在于用尽量少的符号完成对语言的梳理。
3. 词法符号：是一种特殊的文法符号，它不能被继续分解为其他文法符号。
4. 字符：单个ASCII符号或者UTF符号。
5. 状态码：标记字符，在词法分析中有相似的性质的字符会被分配相同状态码。
6. first集：任意文法符号M，假定以M做为开始符号，所推导出的所有句子的第一个终结符号所组成的集合。
7. follow集：任意文法符号M，在仅仅不对M进行推导的情况下，在所有产生式推导出的所有句子中，出现在M右侧的第一个终结符号所组成的集合。

# 功能边界确定
需要包含以下几个组件和附件：

1. 一个需要指定关键字的词法分析器
2. 一个语法分析器，包含LL(1)分析表
3. 一个AST基类
4. 一个文法规则录入工具

# 实现方式
## 1.词法分析器（Lex包）
词法分析器应该为每一个可能读取到的字符设置一个状态码，状态码是用来引导有限自动机进行状态转移的。每个状态码事实上对应了完整的有限自动机的一个子自
动机，在这里表现为一个函数的形式。

由于每种类型的词法符号对应的字符状态都只有几种，这样，在每个子自动机/函数内部，就可以很容易得出现在是否应该继续读入字符并且接续下去，方便进行分
词。

除了单一字符组成的标点符号，多个字符连在一起也有可能分属不同的标点符号，此时需要每次读入符号就判断一次。

需要注意的是，划分字符所属的状态时，如果两个字符的作用有任何不一致，那么一定要分到两个状态码下面去。因为如果分开的话只需要在每个子自动机里多添加
一个节点两条路径；不分开的话就要在不同的节点里写逻辑判断，这样难度更大而且更容易出错。

## 2.语法分析器（Parser包）
### 实现Parser功能需要的组件
Parser的核心由一个主控程序和一个分析表组成，周边包含多个栈，用于存放分析中的中间变量、未完全分析完的文法节点信息和节点的分析位置信息，
Parser的主要功能是根据Lex传递的符号流和分析表内容改写分析栈。

因为在分析的过程中就要动态的构造AST树，所以会有一个基于反射的实例化AST类的工具类。

### 主控程序动态构造AST的过程
构造AST需要涉及到多个栈的配合，因为构造是不能一次性构造完一个文法节点的，所以需要在运行过程中不断进行入栈出栈的操作。

因此，这个过程需要用两个栈：文法节点栈和分析栈栈帧，文法节点栈用于存放尚未完成构造的文法节点，分析栈栈帧用于控制文法节点栈的出栈动作。

栈动作与Parser动作的对应关系如下：
1. 当Parser将分析栈中的非终结符进行替换的时候，文法节点栈将当前AST类压栈，用现在的分析栈长度记录栈帧。
2. 当Parser将分析栈中的终结符弹出时，相当于给当前的文法节点设置属性；单词流和分析栈同时出栈，出栈的变量用于设置属性。
3. 遇到ε产生式直接跳过，不进行操作。
4. 当当前分析栈长度小于栈帧顶层记录的长度时，文法节点栈和分析栈栈帧同时进行出栈动作。

### 表驱动相对于状态驱动的优缺点
缺点：  
1. 状态驱动便于CPU进行分支预测，加快执行速度。
2. 需要使用更多的内存维护数据结构。
3. 无法构造可编译可观测的Java文件实体，只能通过加载序列化字节码进行调用。

优点：
1. 代码实现方便。
2. 便于代码复查和人工debug。
3. 缩减代码体积，尤其针对一个编程语言中可能存在的成百上千个状态来说，效果更明显。

分析表内容请参阅：  
https://github.com/kppomzh/Compilation_Principle/blob/master/3.1.%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E5%88%86%E6%9E%90%E6%B3%95%E7%9A%84%E9%A2%84%E6%B5%8B%E5%88%86%E6%9E%90%E7%A8%8B%E5%BA%8F(Parser)%E5%8E%9F%E7%90%86%E5%8F%8A%E6%9E%84%E9%80%A0.md

### 非LL(1)的LL(k)文法的处理
对于正常的语言，如果仅仅使用LL(1)，那么很大概率会遇到不能处理的文法。比如说对于Oracle SQL来说：  
select [[TableSpace_Name . ]Table_Name . ]List_Name from Table_Name;   
这个句子，按照Oracle的文法来说，是可以省略掉前面的表空间名和表名的。但是对于这几个名称来说，它们的组成结构都是一样的由大写/小写字母、数字、下划
线组成的（稍微简化一下对象名称的定义，否则讨论起来太麻烦）。这样的字符串在词法分析当中会被统一识别为“标识符”，之间并没有区别，唯一能够区别的是他
们所处的位置。  
所以这里的文法，Oracle是这样写的：  
select_list=(schema .)? (table|view .)? (*|list)
这样的话，语法分析器从另一个终结符之后第一次读取标识符的时候，是没有办法立刻判断是应该用schema、table、list来对文法进行推导。这在自顶向下语法
分析中已经说明过的情况，但是由于此时存在中间的非终结符层级，所以标准的LL(1)文法是没有办法处理的。此时就需要自动切换成LL(k)的分析法，继续向后读
取k个符号，来确定当前应该采用哪条产生式。比如对select_list文法来说，当k=4时，即可完全的判定应该采用哪条具体的产生式。
目前该功能尚未实现。

## 3.文法规则解析（GrammarMaker包）
### 文法节点与产生式加载
录入工具的主要作用就是读取文法文件。在这里，为了简化分析步骤，没有采用“文法文件内部引用文法文件”的方案，而是用了“外部配置文件依次加载文法文件”
的方案；并且指定了三个必须加载的文法文件（虽然你可以不往里面写东西），依次为keyword.grammer / mark.grammer / annotation.grammer，分别
代表关键字/符号/注释三类文法符号。

Reader会首先加载这三个文件并将其填到Lex中；然后按行分析grammer.list文件，从上至下加载其中的文件。

所以要求后加载的文件的所有产生式右部使用的文法符号都必须已经包含在先加载和正在加载的文件中，否则会报错表示“文法未定义”。

另外需要注意的是，因为在后来的AST类生成的过程中，由于各种符号本身不能作为变量名称，所以需要在自定义的文法中用其他非终结符来再次定义符号的名称。
否则Java在生成类的时候会报错。　　
这里为了方便调用AST类，所以不能用自动为符号分配随机变量名的方式来完成这个工作。除非哪一天本项目能够生成完整的访问者模式这种风格的分析代码。

### 词法状态分析
词法状态分析，据我所知，大致有两种可选方式。
1. 基于终结符号的状态码分析
2. 基于字母符号的状态码分析
Antlr采用的是第一种方式，将所有的终结符号用关键字显式的指定，所以Antlr的Lex类看起来就像一个Java bean一样，对于所有已定义的终结符都有一个状态码，需要的时候直接从数组中用相对地址
取出对照；这种方式编写状态机较为困难，但是组织文法符号定义很简单。  
本项目采用的是第二种方式，为每一个可能出现的字符都给定一个状态码，这种方式有利于编写状态机，但是在文法符号定义上的限制较大。  
 
本项目在词法符号定义上有以下几个限制：
1. 对文法文件的分析区分大小写；词法分析器采用小写字母进行分析，并且默认会将大写字母转换成小写字母，字符串中除外。
2. 词法符号的组合形式自定义仅限于在keyword.grammer中。
3. 词法符号的组合方法有两种，组合的时候两个符号之间用空格分开；既可以用单独的字符进行组合，也可以用已经存在的词法符号达到批量添加的效果。
4. 未进行组合形式自定义的词法符号（包含三个基本grammer文件中的所有符号），会用其名称中的所有字符做为其组合字符。
5. 固定关键字STRING，用于定义字符串的起始与终结符号，其中所有字符的状态码都会被置3。
6. 固定关键字INTEGER，用于划分所有数字类型的字符，涉及到INTEGER的字符的状态码都会被置2。
7. 固定关键字toLowerCase，用于标记非字符串部分的标识符是否不转换小写。比如希望定义一个名称中含有大写的变量，可以用这里的字符包装起来。
8. 固定关键字EOF，用于划分句子，停止分析。
9. 空格、回车、换行、换页是代表分割单词的显性标识，将会给这四个字符的状态码置0。
10. 固定转义字符是'\'。

一个字符可以出现在多种类型的词法符号后面，除了：
1. STRING中的字符不允许出现在别的词法符号的定义中。
2. EOF中的字符不允许出现在别的词法符号的定义中。
3. toLowerCase中的字符不允许出现在别的词法符号的定义中。

进行词法状态分析的时候，分析器中会内置一个charStatus的参数，用来在出现一个字符用在多种类型的词法符号中的情况下，给这样的字符分配状态码用。
** 未完待续 **

###first集与follow集推导
此后，Reader会计算所有非终结符的follow集（当然会先计算出所有first集），根据这些信息填写Parser的分析表。  
如果按照《编译原理》书中的文字描述直接写first集与follow集的算法也未尝不可，只是那种算法很难写，效果也不见得好；只是适合人类学习演算，而不适合
用在机器上。  
所以需要可以一次扫描就构造出所有文法符号的first集与follow集的算法。  
#### first集递推构造算法
一个文法符号的first集，可以通过深度遍历扫描其所属的所有产生式右部的第一个文法符号来获得：
1. 若右部当前符号是终结符，则直接加入左部非终结符的first集，分支遍历触底。
2. 若右部当前符号是非终结符且first集的长度大于0，则直接将first集加入左部非终结符的first集，分支遍历触底。
3. 若右部当前符号是非终结符且first集的长度为0，那么用这个非终结符的名称，继续递归的向下构造first集。并且在退出递归的时候将first集添加到左部
非终结符的信息中。

#### follow集传递构造算法
因为LL文法当中不可避免的会出现大量的ε终结符，所以follow集涉及到大量非终结符的推理判定。但是书中所述的follow集计算方法又过于繁琐，不方便进行实
现。所以在这里将会对follow集算法进行精确的描述，其中一些模糊的描述将会被精确的动作所替代。  
本算法的目的是在全局范围内，大部分节点的follow集只需要一遍计算就能得出（当然要是非搞一个到处是嵌套的文法来也没办法），局部存在循环的地方按照固
定的可以追溯的方法计算就能得出，避免“反复使用以上几条方法”这种没法确凿实现的语句。  
由于在最开始的时候，我们只能知道开始符号S的follow集，所以就根据follow(S)与全体符号的first集来推算全体符号的follow集。 
为了覆盖全面，构造follow集的时候，需要从开始符号S开始，用依次轮询所有产生式右部的方式逐渐的向下搜索。   
我们先规定几个符号定义：M是产生式左部的非终结符，L是某个产生式右部的一个文法符号，L+1是L右侧紧连着的第一个符号。  
由此得到follow集的一般构造算法：
1. 声明一份“无依赖文法节点”列表S。
2. 从左到右扫描每条产生式右部，当L与L+1都是非终结符的时候，记录二者的传递关系Ω(L+1,L):follow(L)=follow(L)&first(L+1)&(ε∈first(L+1)?
follow(L+1):null)，并将L+1从S中移除。
3. 从左到右扫描每条产生式右部，当L是非终结符且L+1是终结符的时候，follow(L)=follow(L)+(L+1)。
4. 扫描到产生式右部结尾的时候，若M与L都是非终结符，记录二者的传递关系Ω(M,L):follow(L)=follow(L)&follow(M)，并将L从S中移除。
5. 所有集合继承关系计算完后，首先按照链式依赖脱钩计算一遍现在已有的和将要变成的无依赖节点，这些节点必然在从根节点出发的某条没有环的路径上。
6. 计算完从根节点出发的链式依赖之后，选出所有环的代表节点，对每个环按照环式依赖脱钩的办法解开环间依赖，然后从环上每个节点单独向下进行链式依赖的
计算。
需要注意的是，2和4两条规则所存储的关系并不一样，一定不能保存在一起。

上述几条只是记录了集合间的传递关系，实际传递过程中则有链式依赖和环式依赖的不同处理方法。
链式依赖：
1. 对于链式依赖来讲，一定有一个“已经”不依赖于任何节点向它添加符号到follow集的节点。
2. 遍历这条链最简单的方法是使用递归。（目前我没有找到展开递归成递推的方法，欢迎大家进行改造）
3. 如果在遍历中，发现某个节点还存在依赖/未出现在无依赖节点列表中，那么遍历到此结束，开始向上返回。

环式依赖：（这个方法目前的算法是有缺陷的，越大的环越有可能丢失follow集符号）
以下所述的所有方法都已经在矩阵类ListMatrix中实现。
1. 获取所有能间接的连接到自身的节点集合，这些节点被称为代表节点。
2. 从某个代表节点开始，获取这个代表节点所有能（直接/间接）达到的节点中那些还能（直接/间接）达到代表节点的节点，也就是在同一个环上的所有节点。
3. 从这个代表节点开始递归遍历，运行两次，第二次开始拆除环间节点的依赖。
4. 对环上的每个节点向下进行一次链式遍历。

#### 环的判定方案
由于计算follow集的时候需要考察各节点之间的依赖顺序，所以就可能出现循环依赖的场面。
这个时候就必须采用重复计算的方法保证每个节点继承到的follow集合都是完整的
环的判定有几种方法，第一是用邻接表（经过改造）记录所有直接和间接可达的子节点；这样的优点是相对节约内存空间。
第二种方案是用可达性算法，这种方法不用对数据结构进行修改，但是不适用于可能出现大量环的场合；因为计算通路费时费力，而且很难处理一条通路上存在多个
重叠节点环的问题。
第三种方案是用邻接矩阵先记录所有直接相连的节点，然后用沃舍尔算法求传递闭包（如果需要间接连接信息）；这种方法比较消耗内存，但是运行时间只有O(n^3^)。
所以更倾向于使用第三种方案来处理环。
##### 层级树（HierarchicalTree）
该方案被否决，至少是暂时被否决。
层级树表示节点从根节点向下的访问顺序，详情请见HierarchicalTree类的JavaDoc。
层级树有三个泛型，分别是K、V extends Colloection、D，D是V的内容
API如下：
1. getRoot()：获取根节点。
2. getMaxLevel()：获取最大节点层级，也就是树的高度。
3. size()：获取节点数量，最少是1。
4. put(K key,K fatherNodeKey)：添加一个节点，并指定其父结点，同时添加一个空的value。如果key已经存在，则只添加和父结点的连接关系。
5. addValue(K key,V value)：为key添加属性集合。
6. addValue(K key,D value)：向key对应的value中添加属性。
7. get(K key)：获取key对应的属性集合。
8. getChildNodes(K fatherKey)：获取key对应的所有子节点。
##### 邻接矩阵（ListMatrix）
邻接矩阵类中为了调用简便减少计算量，所以有两个矩阵，一个是只有节点间直接连接关系，另一个包含了所有间接连接关系。
API如下：
1. add(K contains)：添加矩阵节点
2. addConnect(K from, K to)：添加一条直接连接
3. isConnect(K from, K to)：判断两个节点是否连接，若from或to不存在于矩阵中则直接返回false
4. getStartNodeConnects(K from,boolean directDependence)：统计from连接到的节点，directDependence为真时只考虑直接连接，为假时考虑
间接连接。
5. getEndNodeConnects(K to,boolean directDependence)：作用类似上面的方法，但是方向调转为统计到达to的节点。
6. getLoops(boolean deduplication)：获取所有在环上的节点，deduplication为真时会以随机的方式清理同一条环路上的多个节点，只留下一个代表
节点。
7. getOnLoopNodes(K Representative)：统计与Representative在同一个环上的所有节点，包含Representative。

## 4.文法性质归纳与检查（ASTPropertiesMaker类）
我们现在已知每个文法符号所能推导出的所有符号和结构，但是这些结构有什么性质？对此暂时还一无所知。 
如果不能具体的知道每一个文法符号都会表现出哪些性质，那么自动的生成语法树的JavaBean类也就是难度极大的任务；暴力罗列可能的性质虽然不也不是不可行，
但是只要稍微复杂的文法，就会出现丢三落四、左支右绌的情况。  
因此我们还需要再一次的梳理所有文法，挖掘文法产生式间的关系和结构。  

### 形式系统简单定义
借用编译原理/计算机程序的名词来描述形式系统的话，形式系统大概由以下要素组成：
1. 一群有限数量，且可用于文法/程序代码的符号集合。
2. 一套语法规则，说明了如何以上述符号建构形式良好的文法表达式/程序语句。通常会要求有一个判定句子是否符合语法规则的算法。
3. 一些附着在语法规则上的语义规则，用来具体落实代码的功能。这可以大致视为对一些公理的陈述。
4. 执行程序的工具，它们本身也可以是程序。大致相当于形式系统中的推理规则，用来调用/控制怎么使用上述符号、语法、语义规则。

### 文法化简
#### 无用符号分析
文法化简的第一步是清除文法产生式中从未被使用的文法符号，所谓从未被使用的文法符号，我们可以从以下两个角度去理解：
1. 文法有显式的开始符号，那么没有被这个开始符号直接或者间接能推导出的文法符号都是未被使用的。
2. 文法没有显式的开始符号，从概率考虑，可以认为文法无向图的最大子图以外的所有文法符号都是未被使用的。

如果文法没有显式的开始符号，这种情况其实是不推荐的，因为分析无用符号的时候，只要这个符号能推导出其他的符号，那么就很难认定它没有用。但是我们可以
假设，如果一个符号能与大部分的文法符号产生联通（此时的连通性不能考虑箭头方向）的话，那么极大可能这个文法符号是会被使用的。基于这种假设，我们可以
通过计算最大连通子图的方法来分析哪些文法符号可能是无用的。

不管采用哪种方式来分析无用符号，邻接矩阵都是必不可少的工具。相对来说，有显式开始符号的文法模型在计算无用符号的速度上也优于没有显式开始符号的模型。
从开始符号出发计算所有符号的单向联通路径显然比计算双向联通路径后再计算连通分量简单得多。

#### 去除ε产生式
消除ε产生式的第一条件是语言不能允许空字符串的出现。
尽管允许ε产生式给我们构造文法带来了很大的便利，但是同样也使得文法的分析变得更加复杂
如果一个文法G~1~有以下产生式：
$$
    S \to 01 | 0A1 | 0S1
    A \to 2A | ε
$$
如果简单的删除A->ε这一条产生式，则会得到文法G~2~:
$$
    S \to 01 | 0A1 | 0S1
    A \to 2A
$$

显然，G~2~与G~1~并不相同，阻断了A->ε之后，产生式A->2A和S->0A1当中的A再也无法消除，因此在修改文法之后，要保证在A->2A和S->0A1两条产生式中能
“出现”ε，就只能添加如下两条产生式：
$$
    S \to 01
    A \to 2
$$

由于S->01已经存在于现有产生式集合里，所以新的与G~1~等价的G~3~文法如下：
$$
    S \to 01 | 0A1 | 0S1
    A \to 2A | 2
$$
** 未完待续 **

#### 去除单一产生式组
标准的LL文法去除二义性的方法是在文法中加入很多中间符号

### AST类生成信息采集
AST类信息的采集，本质上是对于一个已知的形式系统提取性质的工作。  
什么叫做“提取形式系统的性质”？比如给定一个程序，所有输入参数都已经确定的情况下，通过对文法/语法的静态分析，观察一段程序中是否存在诸如死循环、除
数为0、变量未定义/未赋值、空指针引用、数组越界这样的语法甚至是语义错误。如果从正面的辅助程序运行的方向来考虑，也可以帮助做到诸如确定弱类型定义、
代码优化、隐式类型转换这样的工作。  
在这里，分析程序所需要做的工作是分析一个非终结符所能推导出的全部符号，在这个非终结符的文法当中的性质。比如说，insert into values中，values
后面跟随的表达式的数量可以有无穷多个，我们不能到了运行的时候无限的跟着分配变量名，必须事先在AST生成之前就分析出来这里可能会有无数个类似的符号，
从而决定用Collection类型来存储这些可能出现的符号。
再分析每个文法节点自身的性质，简化一些循环结构的子树。然后生成AST类供运行时存储分析结果。

目前想要在这里提取出的性质有以下几点：
1. 该节点是否与终结符等价？
2. 该节点是否是直接右递归的？（包含所有产生式都是右递归或者只有一部分产生式右递归）
3. 该节点是否仅仅是为了保持某些节点的循环而设计的？（消除左递归以及不定长数组）
4. 该节点是不是一个属性，或者可以表示成哪种变量的属性？
5. 文法中是否存在死循环？
这些性质将会被填充到childNodeProperties中，并且传递给BranchTreeNode类用于生成AST类。

#### 终结符等价
如果一个非终结符与终结符等价，当且仅当这个非终结符只有一个产生式，且该产生式只能推导出一个终结符的情况。  
一般出现这种情况的原因都是当一个终结符本身带有确实的语法含义，并且需要作为AST中的一个组成部分的时候。此时这个非终结符在分析程序中的表现应该是一
个Boolean型的Attribute，判断为真的条件是对应的终结符是否出现。

#### 循环节点判定
1. 如果一个非终结符仅包含多条有效产生式，并且在这些产生式中，既存在以该非终结符位结尾的，也存在不以该非终结符做结尾的，那么这是一个正常的循环节
点。
2. 如果一个非终结符仅包含多条有效产生式和一条空产生式，并且有效产生式是右递归的，并且以“终结符 非终结符 非终结符（本身）”的形式组织，
且每条产生式中间的非终结符都一致；即可认为它是一个过渡节点，此时将不对它生成AST类，而将中间的非终结符设置为循环节点。
3. 如果一条文法产生式存在多个完全相同的子部分串联起来的话，意味着包含某些隐式的有限循环。
另外，对于类似标准SQL中union这样的结构而言，并不能算在“为了保持循环而设计”的范畴。

#### 属性节点判定
1. 假如一个非终结符中的所有产生式右部都只有一个终结符，那么这是一表示属性的非终结符。
2. 假如一个非终结符A中的所有产生式右部都只有一个非终结符B，并且所有B满足第一条性质（与终结符等价），那么取消B的层级，用B的名称指代终结符。
3. 如果一条产生式右部的中间出现了一些终结符，那么是可以抛弃的终结符。
4. 如果一条产生式的右部表示为一个赋值，且产生式本身没有循环，那么可以设置一个属性。
5. 产生ε的产生式不算在内。
这里的第二条实际上与去除单一产生式组类似，但是细节处理有所不同。

#### 死循环判定 
可能有的人照搬一些书上的原话：停机问题是不能被计算机判断的。这个话没有错，但是我们现在判断的不是一个具体程序，只是一套字符串改写规则的有效生成形
式，在这种情况下，我们是可以对其中的一些性质做出预言的。  
举一个最简单的例子，如果经过扫描，发现某个文法形如：$$ A \to aAB $$ $$ B \to b | ε $$，且对于非终结符A仅有一条产生式。那么很明显，从开始
符号S逐渐展开的话，无论如何是不可能将B改写成b或者ε的；因为A只能被改写成aAB，这种文法即使使用无限的步骤也不可能将A推导成一个确定的终结符串，因
此这是一个典型的死循环文法。  
那么除了这种直接可见的死循环之外，还存在着由间接递归造成的死循环，这种情况更为隐蔽；但是我们仍然可以使用一定的方法来进行分析。  
目前的实现仅对直接右递归进行分析。  

按照上面的说明扫描完AST类的基本信息之后，就可以按照makeBranchTreeNode类中预先设置的模板方法来生成一个节点的各种对象

## 5.AST自动生成（JavaPoet包 与 Tree_Span包）
每个文法节点均包含三个通用protected方法：①添加子节点 ②设置属性 ③获取所有子节点

另外还有一个通用属性“节点名称”以及对应的get/set方法。

三个protected方法是用于继承并且重写的，根据每个节点的不同会有所变化。三个protected方法重写的规则是这样的：
### 1. 添加子节点
一般来说，如果一条文法产生式中存在表述复杂的非终结符，那么就需要添加子节点，表示这个地方还有很复杂的展开，需要继续向下寻找详细的处理过程。
如果这样的节点有很多的话，可以加一个Collection类来方便遍历；推荐用List，因为很多语言的代码顺序和处理顺序是相关的。
### 2. 添加属性
有两种情况，如果一个非终结符是由多条简单的只包含终结符的产生式组成的，那么很大概率这个非终结符代表的是某种属性。另外一种可能就是多条产生式的形式
类似，但是中间有一个关键终结符不一样，那么很可能那里就是一个属性。
### 3.获取所有子节点
将第一条所述的所有Collection类集中到一个Collection中输出。应该说这种方法不会很常用。

### AST类填充工具类（makeBranchTreeNode）
填充工具类提供对上面所述的通用方法以及各种AST类性质的代码生成。  
API如下：  
1. buildFile()：生成Java文件，并返回其文件对象。
2. AnalysisChildPropClass()：按照该非终结符的文法信息生成AST类中的方法。
3. AnalysisAttrTerminal()：生成终结符的对应布尔属性。
4. makeExtendMethodBuilder()：生成默认的三个方法。

# 未来改进计划
1. 本质上S作为开始符号不是一个显式的过程，但是现在的实现并没有设计这部分，所以只能规定写上S的产生式并暂且规定S不能出现在任何产生式的右部；以后
解析文法规则的时候，可以不用显式指定最顶层的几条文法规则到一个固定的开始符号上。  
这里可以细化到用语言的定义名称来指定开始符号所在的类文件名称，语言的定义名称则用grammlist的第一个文法文件名来命名。  
2. 虽然有了对词法符号进行分析的功能，但是对于状态的分析结果并不能正确的填写到词法解析器的对应位置。只能对常用的几个状态码写死。
3. 语法解析修改为自适应LL(k)的形式，以便解决某些不属于LL(1)但属于LL文法的表达式解析。  
5. 对于右递归文法的分析，现在这篇文档里写的并不能精确的分辨各种右递归的差别。
6. 根据更加高级的形式语言学知识，将分析过程简化，省略掉繁琐的follow集分析以及ε判断。
7. 试图取消为了衔接非终结符与终结符的中间层级，不过这个优先级靠后，因为目前看来分辨右递归类型的任务还是要靠这个中间层才能完成。
8. 没有完全发挥出文法分析的能力，例如分析出一个非终结符的循环状态的时候，不能指示Parser按照对待循环的方式向List中加入变量，只能按层级展开。

## 后注
虽然看上去Antlr的终结符定义方法确实很好，但是用那种方法定义的终结符并不完全适合进行常规的LL文法分析。在某些极端的情况下会造成下推的冲突。类似于
LL分析中的提取左侧公因子。Antlr用优先级的方式处理了这个问题，但是本文档并没有处理方法。